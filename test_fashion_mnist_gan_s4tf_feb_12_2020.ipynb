{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_fashion_mnist_on_gan_s4tf_feb_12_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/8bitmp3/testing-s4tf-things/blob/master/test_fashion_mnist_gan_s4tf_feb_12_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxfIZrWwmOg-",
        "colab_type": "text"
      },
      "source": [
        "## Testing FashionMNIST on a GAN\n",
        "\n",
        "New dataset: \n",
        "https://github.com/brettkoonce/swift-models/blob/fashion-mnist/Datasets/MNIST/FashionMNIST.swift (code author: @brettkoonce)\n",
        "\n",
        "GAN and various packages: https://github.com/tensorflow/swift-models/ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQmgVWz5ufGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Foundation\n",
        "import TensorFlow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXiJN8VvbQ-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// https://github.com/tensorflow/swift-models/blob/master/Support/Stderr.swift\n",
        "\n",
        "var stderr = FileHandle.standardError\n",
        "\n",
        "extension FileHandle: TextOutputStream {\n",
        "    public func write(_ string: String) {\n",
        "        guard let data = string.data(using: .utf8) else { return }\n",
        "        self.write(data)\n",
        "    }\n",
        "}\n",
        "\n",
        "public func printError(_ message: String) {\n",
        "    print(message, to: &stderr)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQADyWzTcTOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// https://github.com/tensorflow/swift-models/blob/master/Support/FileManagement.swift\n",
        "\n",
        "#if canImport(FoundationNetworking)\n",
        "    import FoundationNetworking\n",
        "#endif\n",
        "\n",
        "public func createDirectoryIfMissing(at path: String) throws {\n",
        "    guard !FileManager.default.fileExists(atPath: path) else { return }\n",
        "    try FileManager.default.createDirectory(\n",
        "        atPath: path,\n",
        "        withIntermediateDirectories: true,\n",
        "        attributes: nil)\n",
        "}\n",
        "\n",
        "public func download(from source: URL, to destinationDirectory: URL) throws {\n",
        "    try createDirectoryIfMissing(at: destinationDirectory.path)\n",
        "\n",
        "    let fileName = source.lastPathComponent\n",
        "    let destinationFile = destinationDirectory.appendingPathComponent(fileName).path\n",
        "\n",
        "    let downloadedFile = try Data(contentsOf: source)\n",
        "    try downloadedFile.write(to: URL(fileURLWithPath: destinationFile))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M28gcFIEbPiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// https://github.com/tensorflow/swift-models/blob/master/Datasets/DatasetUtilities.swift\n",
        "\n",
        "#if canImport(FoundationNetworking)\n",
        "    import FoundationNetworking\n",
        "#endif\n",
        "\n",
        "public enum DatasetUtilities {\n",
        "    public static let currentWorkingDirectoryURL = URL(\n",
        "        fileURLWithPath: FileManager.default.currentDirectoryPath)\n",
        "\n",
        "    public static func downloadResource(\n",
        "        filename: String,\n",
        "        fileExtension: String,\n",
        "        remoteRoot: URL,\n",
        "        localStorageDirectory: URL = currentWorkingDirectoryURL\n",
        "    ) -> URL {\n",
        "        printError(\"Loading resource: \\(filename)\")\n",
        "\n",
        "        let resource = ResourceDefinition(\n",
        "            filename: filename,\n",
        "            fileExtension: fileExtension,\n",
        "            remoteRoot: remoteRoot,\n",
        "            localStorageDirectory: localStorageDirectory)\n",
        "\n",
        "        let localURL = resource.localURL\n",
        "\n",
        "        if !FileManager.default.fileExists(atPath: localURL.path) {\n",
        "            printError(\n",
        "                \"File does not exist locally at expected path: \\(localURL.path) and must be fetched\"\n",
        "            )\n",
        "            fetchFromRemoteAndSave(resource)\n",
        "        }\n",
        "\n",
        "        return localURL\n",
        "    }\n",
        "\n",
        "    public static func fetchResource(\n",
        "        filename: String,\n",
        "        fileExtension: String,\n",
        "        remoteRoot: URL,\n",
        "        localStorageDirectory: URL = currentWorkingDirectoryURL\n",
        "    ) -> Data {\n",
        "        let localURL = DatasetUtilities.downloadResource(\n",
        "            filename: filename, fileExtension: fileExtension, remoteRoot: remoteRoot,\n",
        "            localStorageDirectory: localStorageDirectory)\n",
        "\n",
        "        do {\n",
        "            let data = try Data(contentsOf: localURL)\n",
        "            return data\n",
        "        } catch {\n",
        "            fatalError(\"Failed to contents of resource: \\(localURL)\")\n",
        "        }\n",
        "    }\n",
        "\n",
        "    struct ResourceDefinition {\n",
        "        let filename: String\n",
        "        let fileExtension: String\n",
        "        let remoteRoot: URL\n",
        "        let localStorageDirectory: URL\n",
        "\n",
        "        var localURL: URL {\n",
        "            localStorageDirectory.appendingPathComponent(filename)\n",
        "        }\n",
        "\n",
        "        var remoteURL: URL {\n",
        "            remoteRoot.appendingPathComponent(filename).appendingPathExtension(fileExtension)\n",
        "        }\n",
        "\n",
        "        var archiveURL: URL {\n",
        "            localURL.appendingPathExtension(fileExtension)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    static func fetchFromRemoteAndSave(_ resource: ResourceDefinition) {\n",
        "        let remoteLocation = resource.remoteURL\n",
        "        let archiveLocation = resource.localStorageDirectory\n",
        "\n",
        "        do {\n",
        "            printError(\"Fetching URL: \\(remoteLocation)...\")\n",
        "            try download(from: remoteLocation, to: archiveLocation)\n",
        "        } catch {\n",
        "            fatalError(\"Failed to fetch and save resource with error: \\(error)\")\n",
        "        }\n",
        "        printError(\"Archive saved to: \\(archiveLocation.path)\")\n",
        "\n",
        "        extractArchive(for: resource)\n",
        "    }\n",
        "\n",
        "    static func extractArchive(for resource: ResourceDefinition) {\n",
        "        printError(\"Extracting archive...\")\n",
        "\n",
        "        let archivePath = resource.archiveURL.path\n",
        "\n",
        "        #if os(macOS)\n",
        "            let binaryLocation = \"/usr/bin/\"\n",
        "        #else\n",
        "            let binaryLocation = \"/bin/\"\n",
        "        #endif\n",
        "\n",
        "        let toolName: String\n",
        "        let arguments: [String]\n",
        "        switch resource.fileExtension {\n",
        "        case \"gz\":\n",
        "            toolName = \"gunzip\"\n",
        "            arguments = [archivePath]\n",
        "        case \"tar.gz\", \"tgz\":\n",
        "            toolName = \"tar\"\n",
        "            arguments = [\"xzf\", archivePath, \"-C\", resource.localStorageDirectory.path]\n",
        "        default:\n",
        "            printError(\"Unable to find archiver for extension \\(resource.fileExtension).\")\n",
        "            exit(-1)\n",
        "        }\n",
        "        let toolLocation = \"\\(binaryLocation)\\(toolName)\"\n",
        "\n",
        "        let task = Process()\n",
        "        task.executableURL = URL(fileURLWithPath: toolLocation)\n",
        "        task.arguments = arguments\n",
        "        do {\n",
        "            try task.run()\n",
        "            task.waitUntilExit()\n",
        "        } catch {\n",
        "            printError(\"Failed to extract \\(archivePath) with error: \\(error)\")\n",
        "            exit(-1)\n",
        "        }\n",
        "\n",
        "        if FileManager.default.fileExists(atPath: archivePath) {\n",
        "            do {\n",
        "                try FileManager.default.removeItem(atPath: archivePath)\n",
        "            } catch {\n",
        "                printError(\"Could not remove archive, error: \\(error)\")\n",
        "                exit(-1)\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvRyaJbIcFAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// https://github.com/tensorflow/swift-models/blob/master/Datasets/LabeledExample.swift\n",
        "\n",
        "public struct LabeledExample: TensorGroup {\n",
        "    public var label: Tensor<Int32>\n",
        "    public var data: Tensor<Float>\n",
        "\n",
        "    public init(label: Tensor<Int32>, data: Tensor<Float>) {\n",
        "        self.label = label\n",
        "        self.data = data\n",
        "    }\n",
        "\n",
        "    public init<C: RandomAccessCollection>(\n",
        "        _handles: C\n",
        "    ) where C.Element: _AnyTensorHandle {\n",
        "        precondition(_handles.count == 2)\n",
        "        let labelIndex = _handles.startIndex\n",
        "        let dataIndex = _handles.index(labelIndex, offsetBy: 1)\n",
        "        label = Tensor<Int32>(handle: TensorHandle<Int32>(handle: _handles[labelIndex]))\n",
        "        data = Tensor<Float>(handle: TensorHandle<Float>(handle: _handles[dataIndex]))\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12aDQIVTa1Vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// https://github.com/tensorflow/swift-models/blob/master/Datasets/ImageClassificationDataset.swift\n",
        "\n",
        "public protocol ImageClassificationDataset {\n",
        "    init()\n",
        "    var trainingDataset: Dataset<LabeledExample> { get }\n",
        "    var testDataset: Dataset<LabeledExample> { get }\n",
        "    var trainingExampleCount: Int { get }\n",
        "    var testExampleCount: Int { get }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JTNyVRgaowr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// The FashionMNIST dataset\n",
        "// https://github.com/brettkoonce/swift-models/blob/fashion-mnist/Datasets/MNIST/FashionMNIST.swift\n",
        "\n",
        "public struct FashionMNIST: ImageClassificationDataset {\n",
        "    public let trainingDataset: Dataset<LabeledExample>\n",
        "    public let testDataset: Dataset<LabeledExample>\n",
        "    public let trainingExampleCount = 60000\n",
        "    public let testExampleCount = 10000\n",
        "\n",
        "    public init() {\n",
        "        self.init(flattening: false, normalizing: false)\n",
        "    }\n",
        "\n",
        "    public init(\n",
        "        flattening: Bool = false, normalizing: Bool = false,\n",
        "        localStorageDirectory: URL = FileManager.default.temporaryDirectory.appendingPathComponent(\n",
        "            \"FashionMNIST\")\n",
        "    ) {\n",
        "        self.trainingDataset = Dataset<LabeledExample>(\n",
        "            elements: fetchDataset(\n",
        "                localStorageDirectory: localStorageDirectory,\n",
        "                imagesFilename: \"train-images-idx3-ubyte\",\n",
        "                labelsFilename: \"train-labels-idx1-ubyte\",\n",
        "                flattening: flattening,\n",
        "                normalizing: normalizing))\n",
        "\n",
        "        self.testDataset = Dataset<LabeledExample>(\n",
        "            elements: fetchDataset(\n",
        "                localStorageDirectory: localStorageDirectory,\n",
        "                imagesFilename: \"t10k-images-idx3-ubyte\",\n",
        "                labelsFilename: \"t10k-labels-idx1-ubyte\",\n",
        "                flattening: flattening,\n",
        "                normalizing: normalizing))\n",
        "    }\n",
        "}\n",
        "\n",
        "fileprivate func fetchDataset(\n",
        "    localStorageDirectory: URL,\n",
        "    imagesFilename: String,\n",
        "    labelsFilename: String,\n",
        "    flattening: Bool,\n",
        "    normalizing: Bool\n",
        ") -> LabeledExample {\n",
        "    guard let remoteRoot = URL(string: \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/\") else {\n",
        "        fatalError(\"Failed to create FashionMNIST root url: http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/\")\n",
        "    }\n",
        "\n",
        "    let imagesData = DatasetUtilities.fetchResource(\n",
        "        filename: imagesFilename,\n",
        "        fileExtension: \"gz\",\n",
        "        remoteRoot: remoteRoot,\n",
        "        localStorageDirectory: localStorageDirectory)\n",
        "    let labelsData = DatasetUtilities.fetchResource(\n",
        "        filename: labelsFilename,\n",
        "        fileExtension: \"gz\",\n",
        "        remoteRoot: remoteRoot,\n",
        "        localStorageDirectory: localStorageDirectory)\n",
        "\n",
        "    let images = [UInt8](imagesData).dropFirst(16).map(Float.init)\n",
        "    let labels = [UInt8](labelsData).dropFirst(8).map(Int32.init)\n",
        "\n",
        "    let rowCount = labels.count\n",
        "    let (imageWidth, imageHeight) = (28, 28)\n",
        "\n",
        "    if flattening {\n",
        "        var flattenedImages =\n",
        "            Tensor(shape: [rowCount, imageHeight * imageWidth], scalars: images)\n",
        "            / 255.0\n",
        "        if normalizing {\n",
        "            flattenedImages = flattenedImages * 2.0 - 1.0\n",
        "        }\n",
        "        return LabeledExample(label: Tensor(labels), data: flattenedImages)\n",
        "    } else {\n",
        "        return LabeledExample(\n",
        "            label: Tensor(labels),\n",
        "            data:\n",
        "                Tensor(shape: [rowCount, 1, imageHeight, imageWidth], scalars: images)\n",
        "                .transposed(permutation: [0, 2, 3, 1]) / 255  // NHWC\n",
        "        )\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk5fHRwsZhGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// https://github.com/tensorflow/swift-models/blob/master/GAN/main.swift\n",
        "\n",
        "let epochCount = 10\n",
        "let batchSize = 32\n",
        "let outputFolder = \"./output/\"\n",
        "let imageHeight = 28\n",
        "let imageWidth = 28\n",
        "let imageSize = imageHeight * imageWidth\n",
        "let latentSize = 64\n",
        "\n",
        "// Models\n",
        "struct Generator: Layer {\n",
        "    var dense1 = Dense<Float>(\n",
        "        inputSize: latentSize, outputSize: latentSize * 2,\n",
        "        activation: { leakyRelu($0) })\n",
        "\n",
        "    var dense2 = Dense<Float>(\n",
        "        inputSize: latentSize * 2, outputSize: latentSize * 4,\n",
        "        activation: { leakyRelu($0) })\n",
        "\n",
        "    var dense3 = Dense<Float>(\n",
        "        inputSize: latentSize * 4, outputSize: latentSize * 8,\n",
        "        activation: { leakyRelu($0) })\n",
        "\n",
        "    var dense4 = Dense<Float>(\n",
        "        inputSize: latentSize * 8, outputSize: imageSize,\n",
        "        activation: tanh)\n",
        "\n",
        "    var batchnorm1 = BatchNorm<Float>(featureCount: latentSize * 2)\n",
        "    var batchnorm2 = BatchNorm<Float>(featureCount: latentSize * 4)\n",
        "    var batchnorm3 = BatchNorm<Float>(featureCount: latentSize * 8)\n",
        "\n",
        "    @differentiable\n",
        "    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
        "        let x1 = batchnorm1(dense1(input))\n",
        "        let x2 = batchnorm2(dense2(x1))\n",
        "        let x3 = batchnorm3(dense3(x2))\n",
        "        return dense4(x3)\n",
        "    }\n",
        "}\n",
        "\n",
        "struct Discriminator: Layer {\n",
        "    var dense1 = Dense<Float>(\n",
        "        inputSize: imageSize, outputSize: 256,\n",
        "        activation: { leakyRelu($0) })\n",
        "\n",
        "    var dense2 = Dense<Float>(\n",
        "        inputSize: 256, outputSize: 64,\n",
        "        activation: { leakyRelu($0) })\n",
        "\n",
        "    var dense3 = Dense<Float>(\n",
        "        inputSize: 64, outputSize: 16,\n",
        "        activation: { leakyRelu($0) })\n",
        "\n",
        "    var dense4 = Dense<Float>(\n",
        "        inputSize: 16, outputSize: 1,\n",
        "        activation: identity)\n",
        "\n",
        "    @differentiable\n",
        "    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
        "        input.sequenced(through: dense1, dense2, dense3, dense4)\n",
        "    }\n",
        "}\n",
        "\n",
        "// Loss functions\n",
        "@differentiable\n",
        "func generatorLoss(fakeLogits: Tensor<Float>) -> Tensor<Float> {\n",
        "    sigmoidCrossEntropy(\n",
        "        logits: fakeLogits,\n",
        "        labels: Tensor(ones: fakeLogits.shape))\n",
        "}\n",
        "\n",
        "@differentiable\n",
        "func discriminatorLoss(realLogits: Tensor<Float>, fakeLogits: Tensor<Float>) -> Tensor<Float> {\n",
        "    let realLoss = sigmoidCrossEntropy(\n",
        "        logits: realLogits,\n",
        "        labels: Tensor(ones: realLogits.shape))\n",
        "    let fakeLoss = sigmoidCrossEntropy(\n",
        "        logits: fakeLogits,\n",
        "        labels: Tensor(zeros: fakeLogits.shape))\n",
        "    return realLoss + fakeLoss\n",
        "}\n",
        "\n",
        "/// Returns `size` samples of noise vector.\n",
        "func sampleVector(size: Int) -> Tensor<Float> {\n",
        "    Tensor(randomNormal: [size, latentSize])\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGmyL5UpZhht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "dc52b174-8810-4240-b1bb-769d0894e34e"
      },
      "source": [
        "// Modified from https://github.com/tensorflow/swift-models/blob/master/GAN/main.swift\n",
        "\n",
        "let dataset = FashionMNIST(flattening: true, normalizing: true)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading resource: train-images-idx3-ubyte\r\n",
            "File does not exist locally at expected path: /tmp/FashionMNIST/train-images-idx3-ubyte and must be fetched\r\n",
            "Fetching URL: http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz...\n",
            "Archive saved to: /tmp/FashionMNIST\n",
            "Extracting archive...\n",
            "Loading resource: train-labels-idx1-ubyte\n",
            "File does not exist locally at expected path: /tmp/FashionMNIST/train-labels-idx1-ubyte and must be fetched\n",
            "Fetching URL: http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz...\n",
            "Archive saved to: /tmp/FashionMNIST\n",
            "Extracting archive...\n",
            "Loading resource: t10k-images-idx3-ubyte\n",
            "File does not exist locally at expected path: /tmp/FashionMNIST/t10k-images-idx3-ubyte and must be fetched\n",
            "Fetching URL: http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz...\n",
            "Archive saved to: /tmp/FashionMNIST\n",
            "Extracting archive...\n",
            "Loading resource: t10k-labels-idx1-ubyte\n",
            "File does not exist locally at expected path: /tmp/FashionMNIST/t10k-labels-idx1-ubyte and must be fetched\n",
            "Fetching URL: http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz...\n",
            "Archive saved to: /tmp/FashionMNIST\n",
            "Extracting archive...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCS30mYYbe1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// https://github.com/tensorflow/swift-models/blob/master/Support/Image.swift\n",
        "\n",
        "public struct Image {\n",
        "    public enum ByteOrdering {\n",
        "        case bgr\n",
        "        case rgb\n",
        "    }\n",
        "\n",
        "    enum ImageTensor {\n",
        "        case float(data: Tensor<Float>)\n",
        "        case uint8(data: Tensor<UInt8>)\n",
        "    }\n",
        "\n",
        "    let imageData: ImageTensor\n",
        "\n",
        "    public var tensor: Tensor<Float> {\n",
        "        switch self.imageData {\n",
        "        case let .float(data): return data\n",
        "        case let .uint8(data): return Tensor<Float>(data)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    public init(tensor: Tensor<UInt8>) {\n",
        "        self.imageData = .uint8(data: tensor)\n",
        "    }\n",
        "\n",
        "    public init(tensor: Tensor<Float>) {\n",
        "        self.imageData = .float(data: tensor)\n",
        "    }\n",
        "\n",
        "    public init(jpeg url: URL, byteOrdering: ByteOrdering = .rgb) {\n",
        "        let loadedFile = _Raw.readFile(filename: StringTensor(url.absoluteString))\n",
        "        let loadedJpeg = _Raw.decodeJpeg(contents: loadedFile, channels: 3, dctMethod: \"\")\n",
        "        if byteOrdering == .bgr {\n",
        "            self.imageData = .uint8(\n",
        "                data: _Raw.reverse(loadedJpeg, dims: Tensor<Bool>([false, false, false, true])))\n",
        "        } else {\n",
        "            self.imageData = .uint8(data: loadedJpeg)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    public func save(to url: URL, format: _Raw.Format = .grayscale, quality: Int64 = 95) {\n",
        "        let outputImageData: Tensor<UInt8>\n",
        "        switch format {\n",
        "        case .grayscale:\n",
        "            switch self.imageData {\n",
        "            case let .uint8(data): outputImageData = data\n",
        "            case let .float(data):\n",
        "                let lowerBound = data.min(alongAxes: [0, 1])\n",
        "                let upperBound = data.max(alongAxes: [0, 1])\n",
        "                let adjustedData = (data - lowerBound) * (255.0 / (upperBound - lowerBound))\n",
        "                outputImageData = Tensor<UInt8>(adjustedData)\n",
        "            }\n",
        "        case .rgb:\n",
        "            switch self.imageData {\n",
        "            case let .uint8(data): outputImageData = data\n",
        "            case let .float(data):\n",
        "                outputImageData = Tensor<UInt8>(\n",
        "                    _Raw.clipByValue(t: data, clipValueMin: Tensor(0), clipValueMax: Tensor(255)))\n",
        "            }\n",
        "        default:\n",
        "            print(\"Image saving isn't supported for the format \\(format).\")\n",
        "            exit(-1)\n",
        "        }\n",
        "\n",
        "        let encodedJpeg = _Raw.encodeJpeg(\n",
        "            image: outputImageData, format: format, quality: quality, xmpMetadata: \"\")\n",
        "        _Raw.writeFile(filename: StringTensor(url.absoluteString), contents: encodedJpeg)\n",
        "    }\n",
        "\n",
        "    public func resized(to size: (Int, Int)) -> Image {\n",
        "        switch self.imageData {\n",
        "        case let .uint8(data):\n",
        "            return Image(\n",
        "                tensor: _Raw.resizeBilinear(\n",
        "                    images: Tensor<UInt8>([data]),\n",
        "                    size: Tensor<Int32>([Int32(size.0), Int32(size.1)])))\n",
        "        case let .float(data):\n",
        "            return Image(\n",
        "                tensor: _Raw.resizeBilinear(\n",
        "                    images: Tensor<Float>([data]),\n",
        "                    size: Tensor<Int32>([Int32(size.0), Int32(size.1)])))\n",
        "        }\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "public func saveImage(_ tensor: Tensor<Float>, size: (Int, Int), directory: String, name: String)\n",
        "    throws\n",
        "{\n",
        "    try createDirectoryIfMissing(at: directory)\n",
        "    let reshapedTensor = tensor.reshaped(to: [size.0, size.1, 1])\n",
        "    let image = Image(tensor: reshapedTensor)\n",
        "    let outputURL = URL(fileURLWithPath: \"\\(directory)\\(name).jpg\")\n",
        "    image.save(to: outputURL)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMa4YPL8ZlY6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8471d518-2e51-46b2-a65c-4f6fbcb7be3f"
      },
      "source": [
        "// https://github.com/tensorflow/swift-models/blob/master/GAN/main.swift\n",
        "\n",
        "var generator = Generator()\n",
        "var discriminator = Discriminator()\n",
        "\n",
        "let optG = Adam(for: generator, learningRate: 2e-4, beta1: 0.5)\n",
        "let optD = Adam(for: discriminator, learningRate: 2e-4, beta1: 0.5)\n",
        "\n",
        "// Noise vectors and plot function for testing\n",
        "let testImageGridSize = 4\n",
        "let testVector = sampleVector(size: testImageGridSize * testImageGridSize)\n",
        "\n",
        "func saveImageGrid(_ testImage: Tensor<Float>, name: String) throws {\n",
        "    var gridImage = testImage.reshaped(\n",
        "        to: [\n",
        "            testImageGridSize, testImageGridSize,\n",
        "            imageHeight, imageWidth,\n",
        "        ])\n",
        "    // Add padding.\n",
        "    gridImage = gridImage.padded(forSizes: [(0, 0), (0, 0), (1, 1), (1, 1)], with: 1)\n",
        "    // Transpose to create single image.\n",
        "    gridImage = gridImage.transposed(permutation: [0, 2, 1, 3])\n",
        "    gridImage = gridImage.reshaped(\n",
        "        to: [\n",
        "            (imageHeight + 2) * testImageGridSize,\n",
        "            (imageWidth + 2) * testImageGridSize,\n",
        "        ])\n",
        "    // Convert [-1, 1] range to [0, 1] range.\n",
        "    gridImage = (gridImage + 1) / 2\n",
        "\n",
        "    try saveImage(\n",
        "        gridImage, size: (gridImage.shape[0], gridImage.shape[1]), directory: outputFolder,\n",
        "        name: name)\n",
        "}\n",
        "\n",
        "print(\"Start training...\")\n",
        "\n",
        "// Start training loop.\n",
        "for epoch in 1...epochCount {\n",
        "    // Start training phase.\n",
        "    Context.local.learningPhase = .training\n",
        "    let trainingShuffled = dataset.trainingDataset.shuffled(\n",
        "        sampleCount: dataset.trainingExampleCount, randomSeed: Int64(epoch))\n",
        "    for batch in trainingShuffled.batched(batchSize) {\n",
        "        // Perform alternative update.\n",
        "        // Update generator.\n",
        "        let vec1 = sampleVector(size: batchSize)\n",
        "\n",
        "        let ùõÅgenerator = TensorFlow.gradient(at: generator) { generator -> Tensor<Float> in\n",
        "            let fakeImages = generator(vec1)\n",
        "            let fakeLogits = discriminator(fakeImages)\n",
        "            let loss = generatorLoss(fakeLogits: fakeLogits)\n",
        "            return loss\n",
        "        }\n",
        "        optG.update(&generator, along: ùõÅgenerator)\n",
        "\n",
        "        // Update discriminator.\n",
        "        let realImages = batch.data\n",
        "        let vec2 = sampleVector(size: batchSize)\n",
        "        let fakeImages = generator(vec2)\n",
        "\n",
        "        let ùõÅdiscriminator = TensorFlow.gradient(at: discriminator) { discriminator -> Tensor<Float> in\n",
        "            let realLogits = discriminator(realImages)\n",
        "            let fakeLogits = discriminator(fakeImages)\n",
        "            let loss = discriminatorLoss(realLogits: realLogits, fakeLogits: fakeLogits)\n",
        "            return loss\n",
        "        }\n",
        "        optD.update(&discriminator, along: ùõÅdiscriminator)\n",
        "    }\n",
        "\n",
        "    // Start inference phase.\n",
        "    Context.local.learningPhase = .inference\n",
        "    let testImage = generator(testVector)\n",
        "\n",
        "    do {\n",
        "        try saveImageGrid(testImage, name: \"epoch-\\(epoch)-output\")\n",
        "    } catch {\n",
        "        print(\"Could not save image grid with error: \\(error)\")\n",
        "    }\n",
        "\n",
        "    let lossG = generatorLoss(fakeLogits: testImage)\n",
        "    print(\"[Epoch: \\(epoch)] Loss-G: \\(lossG)\")\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "[Epoch: 1] Loss-G: 1.0132707\n",
            "[Epoch: 2] Loss-G: 1.0107026\n",
            "[Epoch: 3] Loss-G: 1.0149908\n",
            "[Epoch: 4] Loss-G: 1.0202806\n",
            "[Epoch: 5] Loss-G: 1.0052707\n",
            "[Epoch: 6] Loss-G: 0.9845302\n",
            "[Epoch: 7] Loss-G: 0.9998964\n",
            "[Epoch: 8] Loss-G: 0.99334157\n",
            "[Epoch: 9] Loss-G: 0.9954661\n",
            "[Epoch: 10] Loss-G: 0.9898559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atOsfqp6luKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}